<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dan</title>
    <description></description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 05 Aug 2019 14:52:17 +0800</pubDate>
    <lastBuildDate>Mon, 05 Aug 2019 14:52:17 +0800</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>大数据笔记 - 分布式系统</title>
        <description>&lt;!-- more --&gt;


&lt;h3&gt;基础概念&lt;/h3&gt;

&lt;h3&gt;存储&lt;/h3&gt;

&lt;h3&gt;计算&lt;/h3&gt;

&lt;h3&gt;附录&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/@leventov/comparison-of-the-open-source-olap-systems-for-big-data-clickhouse-druid-and-pinot-8e042a5ed1c7&quot;&gt;Comparison of the Open Source OLAP Systems for Big Data: ClickHouse, Druid and Pinot&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 21 Mar 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2019/03/21/distributed_system/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/03/21/distributed_system/</guid>
        
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>大数据笔记 - spark vs. flink</title>
        <description>&lt;p&gt;先说观点，spark和flink都是目前能够一站式解决lambda架构的计算框架。因为spark出来的早，现在在活跃度、成熟度方面比flink强。flink发展相对较晚，相比spark各个细节做了很多优化。个人觉得二者是同一个世代计算框架的不同实现，细节方面会相互学习、增强。但要说谁能干掉谁，恐怕都没有这能力。&lt;/p&gt;

&lt;!-- more --&gt;


&lt;p&gt;这里从几个方面比较下二者的区别。&lt;/p&gt;

&lt;h3&gt;内存管理&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;SPARK. executor内存管理算是spark的一个软肋。spark并不会直接操操控jvm上堆内内存，只是进行逻辑上的&quot;规划式&quot;的管理。
当jvm起来的时候，executor会维护Storage、Execution的堆内堆外四个内存&lt;em&gt;map&lt;/em&gt;, 分别记录各个块在堆内堆外的内存状态。虽然会有一些防止oom的buffer机制，但这种内存记录器不可能完全准确(比如被spark标记释放的对象可能没有被JVM回收)，所以spark不能完全避免OOM。
&lt;img src=&quot;/images/hadoop/spark_mem_1.png&quot; alt=&quot;note&quot; /&gt;
&lt;img src=&quot;/images/hadoop/spark_mem_2.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;FLINK. 相比spark，flink在内存管理更用心。&lt;br&gt;
① 采用积极的内存管理策略：用专门的内存池负责每个数据片的分配和管理。&lt;br&gt;
② 定制化的数据片操作：高效的二进制操作、量身定制的序列化框架。&lt;br&gt;
&lt;img src=&quot;/images/hadoop/flink_mem_1.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;抽象&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;数据模型. 对于底层数据抽象，rdd(Resilient Distributed Datasets)是spark的灵魂。rdd其实是一种分布式的内存抽象，负责处理内存、磁盘数据的分布式存储、和HA(checkpoints)等。spark在rdd上封装出dataset，不管是batch还是streaming都直接通过dataset操控数据。而flink的底层数据抽象成一种有状态流(stateful stream), 然后分别封装成DataStream和Dataset供streaming和batch任务操作数据。在业界普遍无缝结合batch、streaming任务的趋势下，spark的做法显然更合理点。但是flink考虑到了实时计算的上下文状态的重要性，这点更胜一筹。
&lt;img src=&quot;/images/hadoop/flink_data.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;编程模型. 对于数据处理流，spark和flink本质上是一样的。虽然叫法不一样(spark叫job、stage，flink叫transformation、operator)，但其实都是map-&gt;shuffle-&gt;reduce的dag(有向无环图)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;实时计算&lt;/h3&gt;

&lt;p&gt;在实时计算(streaming)的支持上，flink做的更出色一点。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;窗口. spark对窗口的支持比较弱，只能根据time interval起batch任务。flink对窗口的支持很强大，既能按时间驱动(比如：每30秒)，也能按数据驱动(比如：每100个元素)。而且窗口的类型包括滚动窗口（没有重叠）， 滑动窗口（有重叠），以及会话窗口 （由不活动的间隙所打断）。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;状态. spark streaming不记录数据状态，所以对于一些上下文相关的计算，spark需要借助外部的存储来保存上下文状态。而flink提供了State Backends对历史数据进行保存，比如存在内存(MemoryStateBackend)、文件（FsStateBackend）、外部DB(RocksDBStateBackend)，这样会使得一些上下文相关的计算逻辑更易实现。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;应用层&lt;/h3&gt;

&lt;p&gt;应用层因为spark发展的时间比较久，社区也更活跃点，所以在sql、机器学习的支持都已经做的比较成熟了。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;SQL. 对flink而言，sql层统一了batch和streaming的编程模型。但是由于支持比较晚，各方面还不是很成熟。二者还有一点不同的是，spark的的底层sql解析器是Catalyst，而flink是Calcite。当然，这个差别并没有什么大的意义。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ML：同上，相比spark，flink还有很长的路要走。但是相比spark，flink有个天生的优势。spark由于rdd的不可变性，且不支持状态存储，所以在机器学习的迭代过程中显得力不从心。而flink由于支持状态持久化，所以在算法迭代计算过程中会更方便。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;附录&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-apache-spark-memory-management/index.html&quot;&gt;Apache Spark 内存管理详解&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;http://wuchong.me/blog/2016/04/29/flink-internals-memory-manage/&quot;&gt;Flink 原理与实现：内存管理&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 12 Jan 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2019/01/12/spark_vs_flink/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/01/12/spark_vs_flink/</guid>
        
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>大数据笔记 - 监控系统</title>
        <description>&lt;p&gt;在实际工作中经常碰到这样的监控需求，重点城市的访问流量是否有大的波动、一个广告位的ecpm是否在合理的范围内、机器的CPU利用率是否正常...
经过一段时间case by case的支持，我们想到或许有通用的办法去解决这类问题。&lt;/p&gt;

&lt;!-- more --&gt;


&lt;h3&gt;overview&lt;/h3&gt;

&lt;p&gt;简单来说，各类监控需求都可以总结为判断一条曲线是否正常，横轴是时间，纵轴是PV、单价、CPU利用率等等的曲线。所以我们对监控流程做了这样的改进：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;老流程：产品、运营、开发手工指定监控维度，并根据经验拍板监控规则。这样带来的问题就是监控维度覆盖面比较低、监控规则指定随意、滞后、维护成本高。
&lt;img src=&quot;/images/ops/process_old.PNG&quot; alt=&quot;note&quot; /&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;新流程：自动扫描监控维度，自动学习监控规则。
&lt;img src=&quot;/images/ops/process_new.PNG&quot; alt=&quot;note&quot; /&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;自动化监控&lt;/h3&gt;

&lt;p&gt;监控流程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1 自动扫描监控维度(单维或交叉维度)&lt;/li&gt;
&lt;li&gt;2 对监控时间序列曲线进行分类(平稳、自相似、非平稳)&lt;/li&gt;
&lt;li&gt;3 对不同类别曲线采用不同监控规则(组合策略)&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;时间序列的自相似性&lt;/h4&gt;

&lt;p&gt;在对曲线分类之前，先介绍下我们对时间序列自相似的定义：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;计算公式：对于时间序列t我们按周期长度n划分序列t={t1,t2…tm}, 其中m是周期数。我们采用欧式距离标准差来度量周期间的距离，用若干周期内距离平均值来度量自相似性：
  d(ti) = stdev(linearScale(ti))， 0 &amp;lt; i &amp;lt; n
  sim(t) = mean(d(t1),d(t2)..d(tn))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/images/ops/sim.png&quot; alt=&quot;note&quot; /&gt;&lt;br&gt;
当一条曲线在不同周期内的距离越小，我们认为这条曲线自相似性越高。&lt;br&gt;
&lt;img src=&quot;/images/ops/dis.PNG&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;

&lt;h4&gt;序列分类&lt;/h4&gt;

&lt;p&gt;我们采用以下几个步骤对曲线分类为平稳、自相似、非平稳时间序列：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;平稳曲线： 计算曲线标准差，当波动小于某个阈值，我们认为这条曲线为平稳时间序列。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自相似曲线: 根据监控时效性对曲线划分周期，计算曲线自相似距离，当自相似距离小于某个阈值为自相似曲线。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;非平稳曲线: 不满足以上两个条件。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;监控策略 · 常规监控&lt;/h4&gt;

&lt;p&gt;对于平稳时间序列的监控(这类指标数据一般波动较小 ，而且表现出&lt;em&gt;强业务特性&lt;/em&gt;)，我们多采用比较常规的监控策略。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;同环比&lt;/p&gt;

&lt;p&gt;  环比 : f(t)/f(t-1)&lt;br&gt;
  同比 : f(t)/f(t-c)。c为周期，一般为三分钟、7天、30天等。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;动态阈值&lt;/p&gt;

&lt;p&gt;  历史极值 ：取历史指定若干周期的数据的极值，差值超过 三倍方差 则判定异常。&lt;br&gt;
  移动平均 ：取历史指定若干周期的数据，去除极大、小值(消除历史异常点的影响)取平均。差值超过 三倍方差 则判定异常。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;EWMA
  指数加权移动平均 ：取历史指定若干周期的数据，去除极大、小值(消除历史异常点的影响)：&lt;br&gt;f(t)=αf(t−1)+(1−α)θt&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;监控策略 · 时间序列基线&lt;/h3&gt;

&lt;p&gt;自相似时间序列监控主要面向的业务场景是 分钟级 的流量监控（ 波动大，而且可能极不规律 ）。基于时间序列预测的基本想法是：我们用监控维度的过去 若干个周期 的时间序列去预测下一个周期，用 预测 出来的时间序列作为基线，然后拿当天的时间序列和基线进行 比较 ，超过一定范围则触发告警。解释下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;分钟级: 我们对流量数据按分钟切片，如果有业务波动可以在分钟内发现。&lt;/li&gt;
&lt;li&gt;若干个周期: 我们忽略了季节性等因素，只考虑了一周之内的波动。所以选取了7|14天为历史周期。&lt;/li&gt;
&lt;li&gt;预测: 预测方法用的是EWMA和Holt winters。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;对于相邻周期内相似的时间序列(周期内的波动比较稳定)，通过一般的时间预测方法都能预测出比较好的时间基线。以新闻广告的列表信息流为例，基线和实际序列的差值可以稳定在一定的范围内：
&lt;img src=&quot;/images/ops/ts_1.png&quot; alt=&quot;note&quot; /&gt;
    对于基线和实际序列的偏差阈值的选择有两个办法：3sigma和局部密度估计(Local Outlier Factor)。&lt;/p&gt;

&lt;p&gt;对于相邻周期内不相似的时间序列，比较直接的想法是 转换成自相似时间序列 。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;拉宽时间窗口
以新闻插件广告位为例，由于新闻push会带来流量的飙升，而每天push的时间点又不一样，所以流量的峰值在每天都不太相同。所以分钟级的基线预测不太理想： &lt;img src=&quot;/images/ops/ts_2.png&quot; alt=&quot;note&quot; /&gt;
如果将时间窗口拉大，比如以两个小时为例，则可以减小预测误差：
&lt;img src=&quot;/images/ops/ts_3.png&quot; alt=&quot;note&quot; /&gt;
拉宽时间窗口其实是 牺牲了时效性来平滑时间序列 ，所以通常不太推荐这个方法。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;差分时间序列：这里说的差分包括并不限于对时间序列作n阶差分、转换为增长率(同比或者环比)序列。
以新闻banner广告为例，由于每天的客户数波动较大，所以广告曲线的振幅也不一样。
&lt;img src=&quot;/images/ops/ts_4.png&quot; alt=&quot;note&quot; /&gt;
但是每天曲线的升降趋势却相似，所以转换成变化速度曲线：f`(t) =( f(t)- f(t-n) )/ f(t-n), n为时间跨度。
&lt;img src=&quot;/images/ops/ts_5.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;监控策略 · 相似波&lt;/h4&gt;

&lt;p&gt;由于广告业务的多样性和媒体的推送操作的不确定性(新闻每天不定时的push)，会导致很多维度的广告PV曲线并没有自相似性甚至毫无规律。
 &lt;img src=&quot;/images/ops/ts_6.png&quot; alt=&quot;note&quot; /&gt;
对于这类非平稳曲线，我们监控的主要目标是 波动特性是否在合理的范围 内。所以我们抽取出曲线的波，通过和历史的正常波形进行比较来判断是否异常。&lt;/p&gt;

&lt;h4&gt;波的度量&lt;/h4&gt;

&lt;p&gt; 我们认为一个波的生命周期从上升率大于某个特定值为波的 上升期 ，到达 波峰 后变化率变为负进入 下降期 ，当下降率恢复到某个特定值则为到达 波谷 。在一个波的完整生命周期内我们会抽取出这个波的一些度量：&lt;br /&gt;
* 上升率 ： 波在上升期的增长率&lt;br /&gt;
* 波峰 ： 波的最高值&lt;br /&gt;
* 上半生波长 ：上升期的波长&lt;br /&gt;
* 下半生波长 ：下降期的波长&lt;br /&gt;
* 下降率 ：波在下降期的下降率&lt;br /&gt;
* 波谷 ：波的最低值&lt;br /&gt;
 为了平滑小区间内的波动，我们滑动一个固定宽度的时间窗口。把一个窗口内的点 拟合成一条直线 。&lt;/p&gt;

&lt;h4&gt;波的监控&lt;/h4&gt;

&lt;p&gt; 在波不同的生命周期内我们会触发不同的监控策略，最后组合多个策略判断波动是否异常：&lt;br /&gt;
* 上升率 ：上升期内上升率如果超过历史正常上升率的极大极小值，则标记异常。&lt;br /&gt;
* 波峰 ： 波峰和历史均值的差值超过3个标准差，则标记异常。&lt;br /&gt;
* 上半生波长 ：上半生波长和历史均值的差值超过3个标准差，则标记异常。&lt;br /&gt;
* 下半生波长 ：下半生波长和历史均值的差值超过3个标准差，则标记异常。&lt;br /&gt;
* 下降率 ：下降期内下降率如果超过历史正常下降率的极大极小值，则标记异常。&lt;br /&gt;
* 波谷 ：波谷和历史均值的差值超过3个标准差，则标记异常。&lt;br /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 20 Nov 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/11/20/shark-monitor/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/11/20/shark-monitor/</guid>
        
        
        <category>ops</category>
        
      </item>
    
      <item>
        <title>大数据笔记 - 实时olap</title>
        <description>&lt;p&gt;最近半年花了不少时间在实时olap上，业务场景是全维度实时监控，这里记录下自己的一些思考。
对于大多数大数据底层应用，公司都有很成熟的支持中间件。比如实时消息队列(TDBANK)、KV存储(CKV)、sql on hadoop(tdw)等等。可是实时olap这个场景，基本上都是各个业务自己小规模的玩玩。之前一直想吐槽数据平台不作为，现在自己摸索了这么久才终于明白，实时olap场景的投入产出比 -- 真的有点低。&lt;/p&gt;

&lt;!-- more --&gt;


&lt;p&gt;大数据场景下的实时olap，说简单点就是极致的内存计算，极小的磁盘、网络IO。把那么多的数据全堆到内存，听起来都觉得内存和CPU在燃烧。但是实时查询的实际需求又没那么强烈。像弱olap实时查询场景：比如淘宝实时交易额、实时在线人数，其实都可以通过kv系统解决，没必要把所有数据都放内存。而全维度olap场景，sql on hadoop(spark、kylin、impala)可以很好的做到分钟级响应(秒级真有那么重要？)。
话虽如此，但总有些绕不过去的硬需求需要真正意义上的实时olap。
&lt;br /&gt;&lt;/p&gt;

&lt;h3&gt;OVERVIEW&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;大数据场景下的olap，区别于大多数sql on hadoop解决方案(hive,spark,impala...),实时oalp(click house,druid,pinot,Vertica...)可以真正意义上做到秒级响应。这主要是因为：&lt;br&gt;
① 定制化的数据存储、压缩、索引，可以极大的减少磁盘IO，增加内存计算。&lt;br&gt;
② 类MPP架构，节点间极少的数据交换，网络IO最小化。&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;当然，这也会带来一些限制：&lt;br&gt;
① 特定的存储使得数据更新变得麻烦，所以很难做到数据的更新和细化删除。&lt;br&gt;
② 不支持节点间数据交换的复杂的计算，比如大表间的join、UV计算(一般是近似计算)。&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;最近半年在技术选型的时候稍微了解了下业绩的不少开源方案(click house,druid,pinot)，这里记录下click house和druid在各个环节的异同。&lt;/p&gt;

&lt;h3&gt;架构&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;druid： druid的架构从某种程度来说更分布式，更'MPP'。不同的NODE负责不同的工作，且node都采用master-slave架构。所以druid在大集群下的HA表现更好，当然运维部署也会更复杂点。
&lt;img src=&quot;/images/olap/druid.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;click house：ck从某种意义上是可扩展单机DB，专注于单机上的性能压榨，然后在meta记录集群其他节点信息。这样在运维部署相对简单，但应用层也需要做更多分布式的工作，比如入库自己需要做负载均衡。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;数据入库&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;druid：druid的数据入库相对ck来说有点重，不管是对数据约束还是服务运维。druid支持离线和在线两种入库方式，离线可以和hadoop无缝结合，实时则有专门的realtime node负责数据接入。&lt;/li&gt;
&lt;li&gt;click house：ck则相对简单，数据入库和传统DB类似，比如jdbc连接。但是因为简单，所以应用层需要充分考虑集群的负载。&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;数据存储&lt;/h3&gt;

&lt;p&gt;毫无意外，这类db都会采用列存的存储格式。因为列存可以更好的压缩数据，而且在查询时也能节省非必要的解压IO。为了在查询时快速定位数据，ch和druid都对数据作了索引。不过在&lt;em&gt;数据压缩&lt;/em&gt;、&lt;em&gt;数据索引&lt;/em&gt;、&lt;em&gt;数据备份&lt;/em&gt;方面，二者有些小的差别。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;druid：druid的存储文件格式叫segment。包含timestamp、维度(Dimensions)、指标(Metrics)三部分。segment文件采用LZ4压缩，另外还会维护一个string-&gt;int的隐射表，避免了文件中有重复的string字符串。这样做是因为int的压缩效率比string几乎多一个量级。在索引方面，druid会建个bit map做倒排，这对某些filter场景可以减少很多IO。在数据备份方面，druid有一个高效的balance策略把每个segment存储到不同节点。而且有master记录、监控每个segment的状态。
&lt;img src=&quot;/images/olap/segment.png&quot; alt=&quot;note&quot; /&gt;
&lt;img src=&quot;/images/olap/druid_compresion.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;click house：ck按分区存储数据，定时对分区进行merge。默认用ZSTD压缩。索引只采用了比较简单的主键稀疏索引。稀疏索引虽然更容易做数据压缩，却不能很好的减少数据读取。所以ck更多时候是做全表扫描，但是由于对主键排序和借助&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E5%8D%95%E6%8C%87%E4%BB%A4%E6%B5%81%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%B5%81&quot;&gt;SIMD&lt;/a&gt;,ck的读取效率其实非常高。数据备份ck做的比较静态，每个server会记录哪台server是自己的备份。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;结论&lt;/h3&gt;

&lt;p&gt;这里我贴出&lt;a href=&quot;https://medium.com/@leventov/comparison-of-the-open-source-olap-systems-for-big-data-clickhouse-druid-and-pinot-8e042a5ed1c7&quot;&gt;大牛的对比&lt;/a&gt;。简单来说，在数据和集群规模不大的情况下，ck是一个更好的选择。
&lt;img src=&quot;/images/olap/compare.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;附录&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/@leventov/comparison-of-the-open-source-olap-systems-for-big-data-clickhouse-druid-and-pinot-8e042a5ed1c7&quot;&gt;Comparison of the Open Source OLAP Systems for Big Data: ClickHouse, Druid and Pinot&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 11 Aug 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/08/11/realtime_olap/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/08/11/realtime_olap/</guid>
        
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>大数据笔记 - 大数据计算框架</title>
        <description>&lt;p&gt;大数据计算框架日新月异，而每次计算效率的大幅提升，简单总结就一句话：IO优化。不管是存储，还是计算的优化，都是更少的磁盘IO，更多的内存IO。本文结合本人在自身工作中的经验，主要讲一下对大数据计算效率上的一些思考。&lt;br&gt;&lt;/p&gt;

&lt;!-- more --&gt;


&lt;p&gt;&lt;img src=&quot;/images/hadoop/framework.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;技术选型&lt;/h2&gt;

&lt;p&gt;对大数据查询平台的技术选型，可以从存储和计算两个方面结合自身业务来衡量。&lt;/p&gt;

&lt;h3&gt;存储&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;扫表vs 索引：建索引可以快速locate需要查询的数据，完全省去了对查询不相关数据的读写IO。但是代价却是漫长的建索引过程和大量额外的存储开销。所以建索引适合经常带filter的数据筛选计算和数据维度基数较多的业务场景。对于一些不带filter的查询和大范围时间内的聚合计算业务场景，建索引就显得多余了&lt;/li&gt;
&lt;li&gt;列存vs 行存：相比于传统DB的行存，列存能大量减少磁盘IO。比如更高效的数据压缩、查询不需要解压非相关字段、更好的索引策略等。但是在数据更新场景下，列存会带来一些额外的开销。所以对更新频繁的业务场景，选择列存就要慎重了。&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;计算&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Map reduce vs MPP: 个人觉得二者的边界比较模糊。Map reduce架构扩展性强、可用性高。MPP由于一些不共享约束，使得计算效率相比而言更高(多内存IO，当然对硬件要求也更高)。所以个人觉得，对于一些离线、近实时处理Map reduce架构更可靠(如hive、spark)。而实时计算，多采用MPP架构（比如业界比较流行的计算框架GP、druid、clickhouse等）。&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;数据预处理&lt;/h2&gt;

&lt;p&gt;对于数据计算过程最耗IO的两个步骤：JOIN和GROUP BY，可以在数据预处理阶段节省计算过程的IO。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;预JOIN：大宽表设计，可以省掉计算过程的join IO，这个可能是比较常用的操作，就不多赘述。可能需要考虑的一点是对于经常变动的业务字段，不太适合预JOIN，因为重跑历史数据真的是非常头疼。所以预join的字段最好是不常变动的。&lt;/li&gt;
&lt;li&gt;数据CUBE：预先group by，简单来说就是空间换时间。apache kylin运用的就是这个方法。但是在海量、高维度的业务场景下，野蛮预建cube的存储代价太大。所以我们提出一种基于组合优化的物化cube智能生成方法：
① 从L(n)出发，计算得到满足覆盖率t的所有n-1规模集合L(n-1), 进一步迭代 L(n-2), L(n-3), ...L(n-k), 删选出所有满足最低覆盖率t的组合C；&lt;br&gt;
② 计算每个组合Ci的空间占用Vi 和收益Ri[(r1/r2)*Coverage(pattern)]；&lt;br&gt;
③ 转化为0\1背包问题：在满足空间限制V的情况下，选出最大收益R的集合Q。&lt;br&gt;
简单来说，就是根据历史查询选出综合考虑查询覆盖和空间占用的最佳组合。下图是查询是否命中cube的时间对比。&lt;br&gt;
&lt;img src=&quot;/images/hadoop/cube.PNG&quot; alt=&quot;note&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;查询计划优化&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;分区筛选：根据业务特点可对用户查询添加特定分区筛选条件。举一个我们业务场景的case，当用户查特定广告排期(非分区字段)，我们在查询计划加上了筛选该排期下订单(分区字段)的条件，这样省略了大量非必要分区的读写IO。&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Wed, 20 Jun 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/06/20/shark/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/06/20/shark/</guid>
        
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>大数据笔记 - olap</title>
        <description>&lt;p&gt;OLAP(联机分析处理)只是一个概念，背后是一个数据系统，包括数据接入、数据仓库的建设、数据服务(ad hoc查询、可视化、数据挖掘...)。&lt;/p&gt;

&lt;!-- more --&gt;


&lt;p&gt;这里记录下自己的一些思考。
&lt;br /&gt;&lt;/p&gt;

&lt;h3&gt;数据仓库&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;数据分层：数据为什么要分层存储？&lt;br&gt;
① 原始数据和应用数据的解耦，使得数据结构更加清晰，也能使得原始业务和应用层的变动不会相互影响。&lt;br&gt;
② 减少重复的数据开发，使得很多对外的数据输出可以复用，也能保证对外数据的一致性。&lt;br&gt;
至于怎么分层，业界比较常见的分层方法是：ods（原始日志层）-&gt; dw（数据仓库层）-&gt; dm（数据集市层）-&gt; app（数据产品层）。个人觉得还是看业务本身的复杂性，根据以往的经验，层数往往和运维的复杂度成正比。所以没有必要为了分层而分层，简单好用才是王道。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;数据模型：传统DB可能多采用关系建模(ER建模)，严格符合3范式。这种约束对于在大数据的场景可能过于严格，所以大数据仓库多采用维度建模。而维度模型最常见的是：&lt;br&gt;
① 星形模型。事实表+一级维度表，可读性好，易维护，聚合查询效率高。&lt;br&gt;
② 雪花模型。事实表+多级维度表。数据冗余少，后期维护较复杂。&lt;br&gt;
对于olap查询系统，个人倾向于星形模型，简单易用，可以省去很多麻烦(所以kylin才会只支持星形)。贴一下网上找的模型对比:&lt;br&gt;
&lt;img src=&quot;/images/hadoop/model.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;元数据(meta)：元数据管理是大数据平台的根基，是数据平台能够很好对外提供服务的基础。其中包括数据schema、业务划分、权限管理、数据血缘等等，甚至延伸到存储信息、计算逻辑...&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;ETL&lt;/h3&gt;

&lt;p&gt;除去业务逻辑处理，ETL本质都是join + group by。数据运维、性能优化... ETL大多数问题最后其实都是在处理这两步。join的目的是为了扩展字段成一张宽表(宽表不仅可以简化下游处理逻辑，也能提升处理效率), 但弊端是在回溯历史时带来很大无谓的计算。group by(预聚合)本质上是空间换时间，缺点是存储资源的浪费。&lt;/p&gt;

&lt;h3&gt;olap框架&lt;/h3&gt;

&lt;p&gt;早期的olap框架以sql on hadoop为代表，由于sql on hadoop的底层存储在hdfs，就决定了无法真正做到实时响应。所以最近kylin、druid开始大展身手，不过这二位对资源的要求不少，富人才玩得起。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;sql on hadoop：以hive、impala、presto、Drill、spark为代表。基本思想都是数据存储在hdfs -&gt; 解析sql成查询计划树 -&gt; 翻译查询计划成mr、自定义mpp查询引擎、spark job...。由于spark统一了实时和离线，完美支持了lambda架构，可以说是这类框架的集大成者。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;kylin：kylin并没有多么复杂的算法支撑和底层实现，它的中心思想很简单：空间换时间，预聚合好数据cube。有时候，简单的往往最有效。但kylin的软肋是实时数据，实际场景应该都是T+1的延迟。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;druid：在&lt;a href=&quot;http://dannyhnu.github.io/2018/08/11/realtime_olap/&quot;&gt;另一篇笔记&lt;/a&gt;也有记录，列存+预聚合+倒排索引+MPP内存计算，所以性能还是比较牛的。但是复杂的系统必然会带来运维上的压力。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;附录&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/u010454030/article/details/74589791&quot;&gt;理解数据仓库中星型模型和雪花模型）&lt;/a&gt;&lt;br&gt;
[元数据管理解析]（https://zhuanlan.zhihu.com/p/36136675）&lt;/p&gt;
</description>
        <pubDate>Thu, 21 Sep 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/09/21/olap/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/09/21/olap/</guid>
        
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>ALGO笔记 - LR</title>
        <description>&lt;p&gt;LR一般用来解决二分类问题，表达能力比较弱，可以简单的这样理解：LR是一个拟合因和果的算法，它认为任何结果y必定和一系列因x存在某些关系w。虽然比较朴实，但LR真的是一个万金油的算法，我们在很多工作中(CTR预估、游戏推荐、系统运维...)都用到了。因为LR：&lt;br&gt;&lt;/p&gt;

&lt;!-- more --&gt;


&lt;ol&gt;
&lt;li&gt;简单、有效(数据量大到一定程度，这些模型的效果其实差别并不大), 可解释性好。&lt;/li&gt;
&lt;li&gt;简单易部署，分布式训练算法比较成熟(在大数据场景下，训练速度快、消耗资源少)，适合online learning。&lt;/li&gt;
&lt;li&gt;稳定。&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;基本假设&lt;/h3&gt;

&lt;p&gt;线性回归假设数据服从高斯分布，所以用一个平面(线性决策边界)可以把数据分开。但现实中数据并不都是完美的高斯分布，所以逻辑回归假设数据服从伯努利分布，通过逻辑函数(Sigmoid)作一层隐射，用一个曲面(非线性决策边界)去分开数据。逻辑回归的假设函数形式如下：&lt;br&gt;
&lt;img src=&quot;/images/lr/lr.png&quot; alt=&quot;note&quot; /&gt;
&lt;br&gt;
其实这就是个sigmoid函数，见下图：
&lt;img src=&quot;/images/lr/sigmoid.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;特征工程&lt;/h3&gt;

&lt;p&gt;因为LR比较朴实，表达能力较弱，所以做LR百分之80的工作其实是在做特征工程。毕竟只有找对了&lt;em&gt;因&lt;/em&gt;，才能到达正确的&lt;em&gt;果&lt;/em&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;归一化:
归一化可以提高收敛速度，提高收敛的精度。具体参考&lt;a href=&quot;http://www.cnblogs.com/LBSer/p/4440590.html&quot;&gt;为什么一些机器学习模型需要对数据进行归一化？&lt;/a&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;离散化:
为什么要离散化，这里直接粘贴下网上找的：
&lt;img src=&quot;/images/lr/lisan.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;组合特征:
组合特征和特征离散化其实意义很类似，都是希望在更高阶的空间里找到划分曲面。通过组合低阶特征，提升模型的非线性表达。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;特征相关性
训练的过程当中最好将高度相关的特征去掉：&lt;br&gt;
1) 去掉高度相关的特征会让模型的可解释性更好。&lt;br&gt;
2) 如果模型当中有很多特征高度相关的话，就算损失函数本身收敛了，但实际上参数是没有收敛的，这样会拉低训练的速度。&lt;br&gt;
3) 减少特征，自然会减少训练的时间。&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;GBDT: 在处理特征离散化和组合特征的过程中有些问题需要人工经验来确定，比如&lt;br&gt;
1) 连续变量切分点如何选取？&lt;br&gt;
2) 离散化为多少份合理？&lt;br&gt;
3) 选择哪些特征交叉？多少阶交叉，二阶，三阶或更多？&lt;br&gt;
gbdt对于数据离散，会根据信息增益，客观的选取切分点和份数。而gbdt的叶子节点，其实就是特征组合的结果。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;特征评估: 评估特征好坏的方法有ABtest，卡方检验，单特征AUC等。比较保险点办法就是在ab test系统去测试新加某个维度带来的ctr变化。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;损失函数&lt;/h3&gt;

&lt;p&gt;损失函数衡量的是实际值和预估值的差异。所以有很多函数可以来衡量这个距离：&lt;br&gt;
&lt;img src=&quot;/images/lr/cost.png&quot; alt=&quot;note&quot; /&gt;
LR一般用对数损失：cost(hθ(x),y)=∑i=1m−yilog(hθ(x))−(1−yi)log(1−hθ(x))。原因参考&lt;a href=&quot;https://www.jianshu.com/p/1bf35d61995f&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;

&lt;h3&gt;模型训练&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;样本均衡: LR对样本均衡比较敏感，所以尽量还是保证正负样本1:1的比例。如果样本不均衡，可以参考&lt;a href=&quot;https://www.zhihu.com/question/56662976&quot;&gt;这里&lt;/a&gt;的方法。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;模型训练: lr的训练过程其实是一个无约束问题的求解过程：求最小的θ，使得损失函数最小。常见的最优化方法有梯度下降法、牛顿法和拟牛顿法、共轭梯度法等。GD -&gt; BGD -&gt; SGD。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;模型评估:  // TODO&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;过拟合&amp;amp;欠拟合: // TODO&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;实现框架&lt;/h3&gt;

&lt;p&gt;SGD的分布式实现一直是业界比较关注的问题, 而问题的本质就是怎么减少进程间订单通讯开销、提高高维数据下的可扩展性。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;tree all reduce: spark的实现方式，两阶段树分裂算法。每次迭代会把所有参数广播到各个节点，然后分两阶段reduce到driver汇总更新。不管是速度，还是可扩展性，这种实现方式都比较差，所以spark的MLLib一直被人诟病。
&lt;img src=&quot;/images/lr/spark_sgd.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ps: 参数服务器，将参数和数据都分布式存储、训练、更新。比如&lt;a href=&quot;https://github.com/Angel-ML/angel&quot;&gt;tencent angel&lt;/a&gt;就是这种实现方式。
&lt;img src=&quot;/images/lr/angel_arc.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;collective communication: 集体通信，通过在进程间引入了同步点的概念达到进程间的同步更新。
&lt;img src=&quot;/images/lr/collective_comm.png&quot; alt=&quot;note&quot; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;附录&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/walilk/article/details/51107380&quot;&gt;Coursera ML笔记 - 逻辑回归（Logistic Regression）&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://www.cnblogs.com/batys/p/3298816.html&quot;&gt;逻辑回归：使用SGD(Stochastic Gradient Descent)进行大规模机器学习&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://www.jianshu.com/p/1c2569c894ce&quot;&gt;LR模型的特征归一化和离散化&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;http://mpitutorial.com/tutorials/mpi-broadcast-and-collective-communication/zh_cn/&quot;&gt;MPI 广播以及集体通信&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 24 Jun 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/06/24/lr/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/06/24/lr/</guid>
        
        
        <category>algorithm</category>
        
      </item>
    
      <item>
        <title>编程笔记 - 锁</title>
        <description>&lt;p&gt;为什么要加锁： 因为并发场景下对同一块内存的更新操作会引起bug。怎么加锁？有没有办法避免加锁？这里整理下自己对锁的思考。&lt;/p&gt;

&lt;!-- more --&gt;


&lt;h3&gt;基础概念&lt;/h3&gt;

&lt;p&gt;并发场景下的bug原因一般可归为三类。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;可见性：一个线程对共享变量的修改，另外一个线程能够立刻看到。在多核并发场景下，每个CPU有自己的缓存。当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。所以单个线程的操作并不是马上对其他线程可见。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;原子性：一个或者多个操作在 CPU 执行的过程中不被中断。操作系统按时间片对多线程|进程分时复用，而一条程序语言(多个CPU指令)就可能被切割成多个步骤在多个线程中交叉执行。这中间就不能保证单个线程的一个操作和其他线程不冲突。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;有序性：代码执行顺序和编写顺序一致。高级语言的编译器优化带来的执行顺序问题。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;锁的分类&lt;/h3&gt;

&lt;p&gt;锁的种类繁多，最终不过两点考虑的平衡：保证互斥和减少锁竞争。加锁是为了保证互斥，但毫无疑问会影响执行效率。所以一般会根据业务特点来减少锁竞争，比如减少锁的持有时间、降低锁的请求频率、使用带有协调机制的独占锁，这些机制允许更高的并发性。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;根据加不加锁可以划分为：&lt;br&gt;
① 悲观锁：比较严格，总是假设最坏的情况，每次取数据时都认为其他线程会修改，所以都会加锁阻止其他线程执行。&lt;br&gt;
② 悲观锁：操作时不会上锁，一般通过版本号机制或CAS来实现。&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;根据线程获取锁的顺序划分为：&lt;br&gt;
公平锁：多个线程按照申请锁的顺序来获取锁。&lt;br&gt;
非公平锁：多个线程获取锁的顺序并不是按照申请锁的顺序，所以有可能会造成优先级反转或者饥饿现象。&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;分布式锁&lt;/h3&gt;

&lt;p&gt;分布式锁本质上和单机锁没有差别：在一个集群中，lock只能在同一时间只能被一台机器上的一个线程所拥有。比较流行的实现框架有redis、zk等。&lt;/p&gt;

&lt;h3&gt;java中的锁&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;volatile：这个关键词并不是java特有的，很多编程语言都会采用volatile去解决可见性问题。volatile的含义是禁用CPU缓存，告诉cpu绕过缓存直接操作内存。但这个并不能解决原子问题。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;synchronized：这其实就是java对lock(可重入锁)的封装工具，始终保证一个代码块的访问控制。特别要注意使用synchronized的粒度。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;工具类：Atomic(原子操作类)、ThreadLocal(线程安全的全局变量)、Concurrent(细粒度分段锁+Volatile)...&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;无锁编程&lt;/h3&gt;

&lt;p&gt;无锁编程最容易想到的就是数据不变或者消除共享，没有共享就不用加锁。比如java中的final(数据不变性)、Thread Local Storage(线程本地存储)都是这种思路。但一个大型项目完全无锁是不太现实的，通常都是采用无锁操作或者无锁的数据结构来提供系统性能。当然还有各种无锁的编程模型来实现无锁并发。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;无锁操作：常见的无锁操作有CAS、Copy-on-write等。&lt;br&gt;
① CAS(Compare-and-Swap),即比较并替换，当原始值和期望值一致的时候，替换目标变量的内存地址。CPU的总线锁能保证真正意义上的原子操作，CAS一般加上循环来实现并不是很严格的原子操作(比如ABA问题)&lt;br&gt;
② Copy-on-write。核心思想是空间换时间，复制数据到新内存块，更新完改变引用地址。和很多DB的数据分版本思想类似，只能保证最终一致性。&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;无锁数据结构：常见的无锁数据结构有无锁队列(lock free queue)、无锁容器(b+tree、list、hashmap)等。以无锁队列为例，可以通过链表或者环形数组(ring buffer)+CAS出入队列操作来实现，这其中以Disruptor为优秀代表。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;附录&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://juejin.im/entry/595f074b51882568b0030520&quot;&gt;无锁编程简介&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://coolshell.cn/articles/8239.html&quot;&gt;无锁队列的实现&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 25 Apr 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/04/25/lock/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/04/25/lock/</guid>
        
        
        <category>code</category>
        
      </item>
    
      <item>
        <title>编程笔记 - 并发</title>
        <description>&lt;p&gt;并发其实是个很宏大的话题，简单来说是为了消灭等待，追求更高的处理效率。在单机场景下，并发是为了平衡CPU和内存、IO(磁盘|网络)间的速度差异。在分布式场景下，并发则是为了追求完美的分治：任务、数据切割和单个worker处理能力的平衡。&lt;br&gt;&lt;/p&gt;

&lt;!-- more --&gt;


&lt;p&gt;并发的问题可以分为两类：分工协作、同步互斥。同步互斥在&lt;a href=&quot;http://dannyhnu.github.io/2017/04/25/lock/&quot;&gt;编程笔记 - 锁&lt;/a&gt;已有记录，这里记录下几个分工协作的编程模型(这里请忽略并发、并行的概念差异)。&lt;/p&gt;

&lt;h3&gt;并发模型&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;多线程：多线程模型算是最基本的并发了。记录两个比较常见的问题：&lt;br&gt;
1、进程和线程的区别。进程和线程都是操作系统的基本概念，比较喜欢&lt;a href=&quot;http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html&quot;&gt;这篇文章&lt;/a&gt;的解释。个人的理解是，CPU太快，比内存、IO快太多。所以操作系统对任务按进程划分，分时间片执行提升CPU利用率。但进程的划分太宽泛，所以每个进程内又对任务切割成多个线程执行。不管划分多少级，本质都是为了提高CPU利用率。而这些划分必然会导致有些是共享的（内存），有些又不共享，所以才会有各种协调机制来防止各级内和各级间的资源冲突。&lt;br&gt;
2、java中的多线程。Thread：最直白的线程封装。ExecutorService：更好用的线程池工具类。ForkJoin：分治思想的一种实现（下图）。&lt;br&gt;
&lt;img src=&quot;/images/code/java_joinfork.png&quot; alt=&quot;note&quot; /&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Callback：回调函数算是开销最小的并发了，应用最多的地方是JS，node算是集大成者。优点是简单灵活，缺点是调度层可能变得复杂。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Actor、CSP(通信顺序进程): 二者都是通过借鉴生产者/消费者的模式解耦消息|事件的产生和处理过程。不同的地方是：&lt;br&gt;
1、消息|事件的收发：Actor注重消息的处理单元(Actor),而不是消息传送方式,所以发送消息需要知道对方是谁。而CSP解耦了发送方和接收方，处理单元不需要关心消息的收发是谁。&lt;br&gt;
2、消息|事件的存储：Actor会在本地维护一个mailBox来存储消息。而CSP会类似没Q点机制，使用预先定义的Channel来存储消息。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;协程(微线程)：简单来说，协程是比线程更轻量级的存在。进程、线程都是操作系统的基本调度单位，所以切换会带来一定的开销。而协程是用户控制的任务(函数)切换，系统开销很小。可以这样简单理解，通过生成器(比如python的yield)让函数有了多个出口，转而执行其他代码而不必引起操作系统级别的上下文切换，所以性能会更高。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Fri, 21 Apr 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/04/21/parallel/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/04/21/parallel/</guid>
        
        
        <category>code</category>
        
      </item>
    
      <item>
        <title>ALGO笔记 - 数据结构</title>
        <description>&lt;p&gt;数据结构：顺序、链式、索引、散列&lt;br&gt;&lt;/p&gt;

&lt;!-- more --&gt;


&lt;h3&gt;数组&lt;/h3&gt;

&lt;h3&gt;线性表&lt;/h3&gt;

&lt;h3&gt;栈&lt;/h3&gt;

&lt;h3&gt;队列&lt;/h3&gt;

&lt;h3&gt;串&lt;/h3&gt;

&lt;h3&gt;树&lt;/h3&gt;

&lt;h3&gt;图&lt;/h3&gt;
</description>
        <pubDate>Sat, 21 Mar 2015 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2015/03/21/data_structure/</link>
        <guid isPermaLink="true">http://localhost:4000/2015/03/21/data_structure/</guid>
        
        
        <category>algorithm</category>
        
      </item>
    
  </channel>
</rss>
